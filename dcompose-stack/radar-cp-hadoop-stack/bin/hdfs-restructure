#!/bin/bash

# HDFS restructure version
DOCKER_IMAGE=radarbase/radar-hdfs-restructure:0.5.3
# HDFS restructure script flags
HDFS_RESTRUCTURE_OPTS=(
  --compression gzip
  --deduplicate
  --num-threads 3
  )
OUTPUT_USER=${OUTPUT_USER:-$(id -un)}
OUTPUT_GROUP=${OUTPUT_GROUP:-$(id -gn)}

# HDFS restructure JVM flags
export RADAR_HDFS_RESTRUCTURE_OPTS="$JAVA_OPTS -Xmx4g"
# Without DOCKER_OPTS, run in interactive mode.
# From systemd or cron, override DOCKER_OPTS to remove
# interactive mode, e.g.,
# DOCKER_OPTS="" bin/hdfs-restructure /mydir
DOCKER_OPTS=${DOCKER_OPTS--i}

# For profiling, run e.g. jvisualvm and connect to localhost:$PROFILE_PORT
# after running:
# PROFILE_PORT=9101 bin/hdfs-restructure /mydir
# Note that profiling the application makes it slower.
if [ ! -z $PROFILE_PORT ]; then
  export RADAR_HDFS_RESTRUCTURE_OPTS="$RADAR_HDFS_RESTRUCTURE_OPTS
    -Djava.rmi.server.hostname=${PROFILE_HOST:-localhost}
    -Dcom.sun.management.jmxremote
    -Dcom.sun.management.jmxremote.port=${PROFILE_PORT}
    -Dcom.sun.management.jmxremote.rmi.port=${PROFILE_PORT}
    -Dcom.sun.management.jmxremote.local.only=false
    -Dcom.sun.management.jmxremote.authenticate=false
    -Dcom.sun.management.jmxremote.ssl=false"
  DOCKER_OPTS="$DOCKER_OPTS -p ${PROFILE_PORT}:${PROFILE_PORT}"
fi

if [[ $# -lt 1 || $1 = "-h" || $1 = "--help" ]]; then
   printf "Usage:\n$0 <hdfs path> [<destination directory>]\nThe destination directory defaults to ./output\n"
   exit 1
fi

DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

# Absolute directory to write output to
OUTPUT_DIR=${2:-$DIR/output}
OUTPUT_DIR="$(cd "$(dirname "$OUTPUT_DIR")"; pwd)/$(basename "$OUTPUT_DIR")"

cd $DIR

. lib/util.sh

# Start HDFS if not started already
sudo-linux bin/radar-docker hdfs

# HDFS filename to get
HDFS_FILE=$1
# Internal docker directory to write output to
HDFS_OUTPUT_DIR=/output
# HDFS command to run
HDFS_COMMAND=(
    "${HDFS_RESTRUCTURE_OPTS[@]}"
    -p local-uid=$(id -u ${OUTPUT_USER})
    -p local-gid=$(grep "^${OUTPUT_GROUP}:" /etc/group | cut -d: -f3)
    -n hdfs-namenode-1
    -o "$HDFS_OUTPUT_DIR"
    --tmp-dir "$HDFS_OUTPUT_DIR/+tmp"
    "$HDFS_FILE"
  )

sudo-linux docker run ${DOCKER_OPTS} \
    -t --rm --network hadoop \
    -v "$OUTPUT_DIR:$HDFS_OUTPUT_DIR" \
    -e RADAR_HDFS_RESTRUCTURE_OPTS \
    $DOCKER_IMAGE "${HDFS_COMMAND[@]}"
